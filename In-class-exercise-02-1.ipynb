{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The third In-class-exercise (02/08/2022, 40 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
    "\n",
    "'''\n",
    "Please write your answer here:\n",
    "Research Question:  Which mattress should I buy in amazon.com. We need to collect different kinds of data from the amazon like\n",
    "customer ratings and reviews. Along with that we need to collect brand of the product and the number of reviews the product got.\n",
    "We can analyze the reviews by checking the words in them. We need to analyze at least 500 reviews.\n",
    "\n",
    "Detailed steps for collecting and saving the data:\n",
    "1. Use beautifulSoup for collect information from amazon. \n",
    "2. Using the classname we can extract the reviews.\n",
    "3. I have extracted 1000 reviews and created dataframe and converted it into csv.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data frame is 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrific</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Super!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Wonderful</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Must buy!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Wonderful</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Pretty good</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Review Rating\n",
       "0                 Super!      5\n",
       "1               Terrific      5\n",
       "2              Fabulous!      5\n",
       "3                 Super!      5\n",
       "4    Best in the market!      5\n",
       "..                   ...    ...\n",
       "995               Super!      5\n",
       "996            Wonderful      4\n",
       "997            Must buy!      5\n",
       "998            Wonderful      4\n",
       "999          Pretty good      4\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "mattress = []\n",
    "dom = []\n",
    "\n",
    "for num in range(100):\n",
    "    link = \"https://www.amazon.com/s?k=mattress&crid=2STIKUVVJ5PKR&sprefix=mattress%2Caps%2C100&ref=nb_sb_noss_1\" + str(num)\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    imp_rev = soup.find_all(class_='4_TuVs') \n",
    "    com_Rev = soup.find_all(class_='_3LWZlK _1BLPMq')\n",
    "    for ele, sub_ele in zip(imp_rev, com_rev) : \n",
    "        mattress.append(ele.text) \n",
    "        dom.append(sub_ele.text)\n",
    "        \n",
    "df = pd.DataFrame(list(zip(mattress, dom)), columns =['Review', 'Rating'])  \n",
    "print(\"Length of data frame is {0}\".format(len(df)))\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
    "\n",
    "The following information of the article needs to be collected:\n",
    "\n",
    "(1) Title\n",
    "\n",
    "(2) Venue/journal/conference being published\n",
    "\n",
    "(3) Year\n",
    "\n",
    "(4) Authors\n",
    "\n",
    "(5) Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22024/3978306760.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNoSuchElementException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "\n",
    "def forex_r(base_url, proceeding_ids):\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\hhc0025\\PycharmProjects\\INFO5731\\src\\SIGIR_Data\\chromedriver.exe')\n",
    "        for proceeding_id in proceeding_ids:\n",
    "        comments = pd.DataFrame(\n",
    "            columns=['article_type', 'article_title', 'article_author', 'article_year', 'article_id',\n",
    "                     'article_abstract', 'total_citation', 'total_download', 'pdf_link'])\n",
    "        proceeding_year = proceeding_id[0]\n",
    "        proceeding_url = base_url + proceeding_id[1]\n",
    "    \n",
    "        driver = webdriver.Chrome(\n",
    "            'C://Users//hhc0025//PycharmProjects//INFO5731//src//Lesson4_Collecting_Data//IMDB_Review//driver//chromedriver')\n",
    "        driver.get(proceeding_url)\n",
    "        sessions = driver.find_element_by_xpath(\"/html/body/div[1]/div/main/div[4]/div/div[2]/div[1]/div[1]/div[2]/div/div\")\n",
    "        all_sessions = sessions.text.split('\\n')\n",
    "        print(len(all_sessions))\n",
    "        for i in range(len(all_sessions)):\n",
    "            session_url = proceeding_url+\"?tocHeading=heading\"+str(i+1)\n",
    "            \n",
    "            articles = driver.find_elements_by_class_name(\"issue-item-container\")\n",
    "            for article in articles:\n",
    "                \n",
    "                article_type = article.find_element_by_class_name(\"issue-heading\").text\n",
    "                print(article_type)\n",
    "                if article_type == 'SECTION':\n",
    "                    continue\n",
    "                else:\n",
    "                \n",
    "                    article_information = article.find_element_by_class_name(\"issue-item__content\").text.split('\\n')\n",
    "                    print(article_information)\n",
    "                    \n",
    "                    article_title = article_information[0]\n",
    "                    \n",
    "                    article_author = article_information[1]\n",
    "                \n",
    "                    if len(re.findall(r'2\\d\\d\\d', article_information[2])) > 0:\n",
    "                        article_year = re.findall(r'2\\d\\d\\d', article_information[2])[0]\n",
    "                    else:\n",
    "                        article_year = ''\n",
    "                    \n",
    "\n",
    "                    \n",
    "                    if len(re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\n",
    "                                      article_information[2])) > 0:\n",
    "                        article_url = \\\n",
    "                            re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\n",
    "                                       article_information[2])[0]\n",
    "                    else:\n",
    "                        article_url = ''\n",
    "                    \n",
    "                    if len(article_information)>3:\n",
    "                        article_abstract = article_information[3]\n",
    "                    else:\n",
    "                        article_abstract = ''\n",
    "                    \n",
    "                    if len(article_information)>4:\n",
    "                        total_citation = article_information[4]\n",
    "                    else:\n",
    "                        total_citation = ''\n",
    "                    \n",
    "                    if len(article_information)>5:\n",
    "                        total_download = article_information[5]\n",
    "                    else:\n",
    "                        total_download = ''\n",
    "                    \n",
    "                    try:\n",
    "                        pdf_link = article.find_element_by_class_name(\"btn--icon.simple-tooltip__block--b.red.btn\")\n",
    "                        if pdf_link != None:\n",
    "                            download_link = pdf_link.get_attribute('href')\n",
    "                            print(download_link)\n",
    "                        else:\n",
    "                            download_link = ''\n",
    "                    except NoSuchElementException:\n",
    "                        download_link = ''\n",
    "                    comments.loc[len(comments)] = [article_type, article_title, article_author,article_year,article_url,article_abstract,total_citation,total_download,download_link]\n",
    "        print(comments)\n",
    "        comments.to_csv(str(proceeding_year)+'_sigir_article_information.csv')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    proceeding_ids = [[2020,'10.1145/3397271']]\n",
    "\n",
    "    base_url = 'https://dl.acm.org/doi/proceedings/'\n",
    "    forex_r(base_url,proceeding_ids)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
    "\n",
    "The following information needs to be collected:\n",
    "\n",
    "(1) User_name\n",
    "\n",
    "(2) Posted time\n",
    "\n",
    "(3) Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tweepy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25300/3307470698.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./keys.ipynb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#consumer_key = ''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tweepy'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "%run ./keys.ipynb\n",
    "\n",
    "#consumer_key = ''\n",
    "#consumer_secret = ''\n",
    "#access_token = ''\n",
    "#access_token_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "number_of_tweets = 1500\n",
    "username = []\n",
    "posted_time = []\n",
    "tweets = []\n",
    "\n",
    "for i in tweepy.cursor(api.user_timeline, id= \" #UttarPradeshElections2022\", tweet_mode= \"extended\"):\n",
    "    tweets.append(i.full_text)\n",
    "    username.append(i.author)\n",
    "    posted_time.append(i.created_at)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
